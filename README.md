# Telecom Architecture Advisor (RAG + Streamlit)

AI-powered telecom architecture advisor using Retrieval-Augmented Generation (RAG), hybrid search, and a Streamlit web UI. It integrates with Google Gemini for high-quality responses grounded in a telecom knowledge base.

> For additional architectural deep-dive details, see `docs/ENHANCEMENTS.md`.

## ğŸ¯ Overview

This app helps telecom architects and engineers make informed design decisions. It combines:

- **Google Gemini 2.5 Flash** (LLM via REST API)
- **ChromaDB** vector store with Sentence-Transformers embeddings (all-MiniLM-L6-v2)
- **Hybrid retrieval** (semantic + BM25 keyword)
- **Dynamic knowledge loading** from markdown/PDF/DOCX with metadata
- **Citations** with normalized relevance scoring
- **Streamlit web interface** + interactive CLI
- **Auto-reload** external sources via JSON config

### Key Features
âœ… RAG implementation with vector database  
âœ… Dynamic knowledge ingestion (no hardcoded content)  
âœ… YAML front matter support for metadata  
âœ… Multi-format support (MD, TXT, PDF, DOCX)  
âœ… Hybrid search (semantic + keyword)  
âœ… Conversation history and context awareness  
âœ… Citation tracking with source attribution  
âœ… Export conversations (Markdown, PDF)  
âœ… Analytics dashboard  
âœ… Architecture comparison mode  
âœ… CLI reload command for dynamic updates

## ğŸ—ï¸ Architecture

```
User Input â†’ [Dynamic Knowledge Loading] â†’ ChromaDB + Metadata
                                              â†“
User Query â†’ [Hybrid Search] â†’ Context + History â†’ Prompt â†’ Gemini â†’ Answer + Citations
              â”œâ”€ ChromaDB (semantic vectors)
              â””â”€ BM25 (keyword matching)
```

**Flow:**
1. **Initialization**: Load knowledge from `knowledge_base/` and `knowledge_sources.json`
2. **Ingestion**: Parse front matter â†’ chunk text â†’ embed â†’ store in ChromaDB
3. **Query**: User question â†’ hybrid search â†’ retrieve top-N chunks with metadata
4. **Generation**: Build prompt with context + conversation history â†’ Gemini API
5. **Response**: Answer + citations (topic, domain, relevance, preview)

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.9+** (check with `python3 --version`)
- **pip** (package manager, usually comes with Python)
- **Git** (for cloning, optional)
- **A Google Gemini API key** (free tier available)

### Get a Gemini API key (first time)

1) Open Google AI Studio: https://aistudio.google.com/
2) Sign in with your Google account.
3) Go to "Get API key" (or visit https://ai.google.dev/gemini-api/docs/api-key) and click "Create API key".
4) Select a project (or accept the default) and create the key.
5) Copy the key and keep it secret. Youâ€™ll set it as `GEMINI_API_KEY` below.

Notes:
- Some regions may have restrictions; check availability in the official docs.
- Free tiers and quotas apply; see Googleâ€™s usage and pricing guidance.

### Setup

**Step 1: Clone or navigate to the project directory**
```bash
# If cloning from GitHub:
git clone https://github.com/rgbarathan/AA_LLM.git
cd AA_LLM
```

**Step 2: Create a virtual environment**
```bash
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

**Step 3: Install dependencies**
```bash
pip install -r requirements.txt
```

**Step 4: Configure your Gemini API key**
```bash
# Copy the example env file
cp .env.example .env

# Edit .env and add your GEMINI_API_KEY
# Example:
# GEMINI_API_KEY=your_actual_api_key_here
```

**Step 5: Start the application**

Option A â€” Web Interface (Recommended):
```bash
streamlit run streamlit_app.py
# Opens automatically at http://localhost:8501
```

Option B â€” CLI Mode:
```bash
python telecom_advisor_enhanced.py
# Interactive command-line interface with fallback to Streamlit
```

**Automated Setup (Optional)**
```bash
# For a more automated setup with security checks:
chmod +x setup_secure.sh
./setup_secure.sh
```

See `SETUP_SECURITY.md` for additional security configuration details.

## ï¿½ What you can do

- Chat with the advisor about telecom architecture
- See citations with normalized relevance scores and text previews
- Upload PDFs/DOCX/TXT/MD to expand the knowledge base (UI or CLI)
- Compare architectures (e.g., Microservices vs Monolith)
- View analytics (topics and recent queries)
- Export conversations (Markdown or PDF)
- Reload knowledge sources dynamically without restart

### CLI Commands
When using interactive CLI mode (`python telecom_advisor_enhanced.py`):
- `compare <arch1> vs <arch2>` â€” Compare two architectures
- `upload <file_path>` â€” Upload PDF/DOCX/TXT/MD file
- `reload` â€” Reload external sources from knowledge_sources.json
- `export md` â€” Export conversation to Markdown
- `export pdf` â€” Export conversation to PDF
- `analytics` â€” Show analytics dashboard
- `help` â€” Show available commands
- `quit` or `exit` â€” Exit program

## ğŸ“‚ Key Files

- `telecom_advisor_enhanced.py` â€” Core RAG logic, Gemini integration, CLI, dynamic knowledge loading
- `streamlit_app.py` â€” Web UI (Chat, Compare, Upload, Analytics, Export)
- `requirements.txt` â€” Python dependencies (install with `pip install -r requirements.txt`)
- `.env.example` â€” Template for environment variables (copy to `.env` and fill in your API key)
- `knowledge_base/` â€” Markdown/PDF/DOCX files with domain knowledge (auto-loaded on startup)
- `knowledge_sources.json` â€” Config for external source auto-loading
- `knowledge_sources.example.json` â€” Template for custom knowledge source configuration
- `chroma_db/` â€” Vector database (auto-created, persistent)
- `telecom_advisor.log` â€” Application logs
- `analytics.json` â€” Query analytics (auto-created)

### Optional/Legacy Files
- `AA_LLM.py` â€” Minimal Gemini API example
- `telecom_advisor_rag.py` â€” Original/simple RAG demo
- `SECURITY.md` â€” Security best practices
- `SETUP_SECURITY.md` â€” Automated security setup guide
- `docs/ENHANCEMENTS.md` â€” Detailed enhancement documentation

## âš™ï¸ Configuration

Environment variables (via `.env`):

- `GEMINI_API_KEY` â€” your Google Gemini API key (required)
- `KNOWLEDGE_DIR` â€” custom knowledge directory path (optional, defaults to `knowledge_base`)

Configuration files:

- `knowledge_sources.json` â€” External knowledge sources (auto-loaded on startup)
- `.env` â€” API keys and environment config
- `analytics.json` â€” Query analytics (auto-created)
- `chroma_db/` â€” Vector database (auto-created, persistent)

Logs and data:

- `telecom_advisor.log` â€” app logs (rotating)
- `analytics.json` â€” stores query history and topic stats

## ğŸ“š Knowledge Base (Dynamic Loading)

### Overview
The system now uses **dynamic knowledge loading** instead of hardcoded content. Knowledge is loaded from external files with optional metadata.

### Supported Formats
- **Markdown (.md)**: With optional YAML front matter for metadata
- **Text (.txt)**: Plain text files, can include front matter
- **PDF (.pdf)**: Extracted via PyPDF2
- **Word (.docx)**: Extracted via python-docx

### Adding Knowledge Files

#### Method 1: Drop files in knowledge_base/ (Recommended)
1. Create markdown files in `knowledge_base/` directory
2. Optionally add YAML front matter for metadata:

```markdown
---
topic: 5g
domain: network
priority: high
source_type: seed
---
Your content here. The system will chunk and embed this automatically.
```

**Available metadata fields:**
- `topic`: Category (e.g., microservices, 5g, standards)
- `domain`: Domain area (architecture, network, compliance, infrastructure, services)
- `priority`: high | medium | low
- `source_type`: seed | external | upload
- `source`: Filename (auto-filled if not provided)

#### Method 2: Configure External Sources (Auto-load on startup)
Create or edit `knowledge_sources.json`:

```json
{
  "local_files": [
    {
      "enabled": true,
      "path": "docs/my_document.pdf",
      "topic": "5g",
      "domain": "network"
    }
  ],
  "directories": [
    {
      "enabled": true,
      "path": "knowledge_base",
      "topic": "external",
      "domain": "architecture",
      "recursive": true
    }
  ]
}
```

See `knowledge_sources.example.json` for template.

#### Method 3: Upload via UI or CLI
- **Streamlit UI**: Upload tab â†’ select PDF/DOCX/TXT/MD â†’ set topic/domain â†’ Upload
- **CLI**: Use `upload <file_path>` or `reload` commands

#### Method 4: Programmatic Add
```python
from telecom_advisor_enhanced import add_knowledge_to_db
docs = ["Your custom telecom knowledge..."]
meta = [{"topic": "5g", "domain": "network", "priority": "high"}]
add_knowledge_to_db(docs, meta)
```

### Current Knowledge Included
- **TMF Standards PDFs**: TMF622 (Product Ordering), TMF629 (Customer), TMF638 (Service Inventory)
- **TOGAF PDF**: Enterprise architecture framework (423 chunks)
- **Prompt Engineering DOCX**: AI prompt design
- **Seed Markdown**: Microservices, Monolithic, TM Forum standards

## ğŸ” Retrieval & Citations

- Hybrid search combines semantic similarity (ChromaDB) and keyword BM25
- Citations display topic, domain, a text preview, and relevance (normalized score)

## ğŸ’¡ Usage Examples

### Example 1: Architecture Comparison
```
ğŸ’¬ Your Question: compare microservices vs monolithic for 5G billing

ğŸ¤– Answer: [Detailed comparison with pros/cons, use cases, and recommendations]

ğŸ“š Sources Used:
   [1] microservices (architecture) - Relevance: 1.00
   [2] monolithic (architecture) - Relevance: 1.00
   [3] 5g (network) - Relevance: 0.95
```

### Example 2: Upload Custom Document
```
ğŸ’¬ Your Question: upload ./my_rfp.pdf

âœ“ Added 47 chunks from my_rfp.pdf
```

### Example 3: Standards Inquiry
```
ğŸ’¬ Your Question: What TM Forum APIs should I use for product catalog?

ğŸ¤– Answer: For product catalog management, you should use TMF620 (Product Catalog Management API). This API allows you to manage product offerings, product specifications, and pricing...

ğŸ“š Sources Used:
   [1] standards (compliance) - Relevance: 1.00
```

### Example 4: Analytics Review
```
ğŸ’¬ Your Question: analytics

ğŸ“Š ANALYTICS DASHBOARD
======================================================================
ğŸ“ˆ Total Queries: 127
ğŸ·ï¸  Most Popular Topics:
   - microservices: 34 queries
   - standards: 28 queries
   - 5g: 22 queries
   - cloud_native: 19 queries
   - high_availability: 14 queries
```

## ğŸ¨ Web Interface Features

### Chat Mode ğŸ’¬
- Real-time conversation
- Citation display
- Message history
- Context awareness

### Compare Mode âš–ï¸
- Input two architectures
- Specify context
- Get structured comparison
- Save to conversation

### Upload Mode ğŸ“¤
- Drag-and-drop PDF/DOCX/TXT/MD upload
- Custom tagging (topic/domain)
- Progress feedback
- Knowledge base expansion

### Analytics Mode ğŸ“Š
- Interactive charts
- Topic distribution
- Query history
- Usage metrics

### Export Mode ğŸ’¾
- Markdown export
- PDF export
- Download buttons
- Conversation preview

## ğŸ“š Extended Knowledge Base Coverage

### Core Topics (10 domains):
1. **Microservices Architecture** - Scalability, deployment, patterns
2. **Monolithic Architecture** - Use cases, migration strategies
3. **TM Forum Standards** - ODA, TAM, SID, eTOM, Open APIs
4. **High Availability** - Redundancy, failover, SLAs
5. **Cloud-Native** - Kubernetes, containers, DevOps
6. **5G Architecture** - SBA, network slicing, core functions
7. **NFV & SDN** - Virtualization, orchestration
8. **Edge Computing** - MEC, latency, use cases
9. **IoT Billing** - Device management, pricing models
10. **Event-Driven** - Kafka, async patterns, CQRS

### Expandable via:
- PDF document upload
- Manual knowledge addition in `knowledge_base/` directory
- API integration (future)

## ğŸ”§ Advanced Technical Features

### Hybrid Search Details
- **Semantic Search**: Vector similarity using sentence transformers (all-MiniLM-L6-v2)
- **Keyword Search**: BM25 algorithm for exact term matching
- **Combined Ranking**: Best of both approaches for optimal results
- **Relevance Scoring**: Transparent score display (0.0-1.0 normalized)

### Citation Tracking Details
- Source identification with topic/domain tags
- Relevance metrics and text previews
- Metadata extraction from YAML front matter
- Full traceability from question to answer

### Conversation Management
- Session persistence with context window (last 3 exchanges)
- Thread tracking for multi-turn interactions
- Full conversation export capabilities
- Automatic context injection for follow-up questions

### Analytics & Monitoring
- Real-time query logging to JSON
- Topic tracking and distribution analysis
- Usage pattern identification
- Knowledge gap visualization

## ğŸ“Š Performance Characteristics

- **Query Latency**: ~2-3 seconds (including LLM call)
- **Retrieval Time**: <100ms for hybrid search
- **Knowledge Base**: Scalable to 100K+ chunks
- **Conversation History**: Unlimited (session-based)
- **Concurrent Users**: Limited by Streamlit (use production server for scale)

## ğŸ† Capabilities Summary

âœ… **RAG Implementation** - Full retrieval-augmented generation pipeline  
âœ… **Vector Database** - ChromaDB with persistent storage  
âœ… **Hybrid Search** - Semantic + keyword for comprehensive retrieval  
âœ… **LLM Integration** - Google Gemini 2.5 Flash via REST API  
âœ… **Web Interface** - Modern Streamlit UI with multiple modes  
âœ… **Document Processing** - PDF, DOCX, TXT, MD with metadata  
âœ… **Citations** - Full source attribution with relevance scores  
âœ… **Conversation History** - Context-aware multi-turn interactions  
âœ… **Export Functionality** - Markdown and PDF export  
âœ… **Analytics Dashboard** - Real-time usage metrics and insights  
âœ… **Architecture Comparison** - Side-by-side analysis with structured output  
âœ… **Dynamic Knowledge Loading** - Load sources without restart


## ğŸ§ª Testing & Evaluation

Testing and evaluation artifacts (automated tests, evaluation scripts, and detailed test docs) have been removed from this repository. The core application and runtime scripts remain functional and fully operational. 

For quick sanity checks:
```bash
# 1. Verify Python and dependencies installed
python3 --version
pip list | grep -E "chromadb|streamlit|requests"

# 2. Check if GEMINI_API_KEY is configured
grep GEMINI_API_KEY .env

# 3. Test knowledge base initialization
python3 -c "from telecom_advisor_enhanced import collection; print(f'KB chunks: {collection.count()}')"

# 4. Run a quick manual test via the web interface
streamlit run streamlit_app.py
# Try a sample query: "What is a microservices architecture?"
```

If you need comprehensive automated testing restored, please let me know.

## ğŸ›¡ï¸ Security

Never commit secrets. Use `.env` and see `SETUP_SECURITY.md` and `SECURITY.md` for best practices.

## ğŸ§ª Troubleshooting

### Common Issues

**1. Missing API key error**
```
GEMINI_API_KEY not found in environment variables
```
Solution:
- Create a `.env` file in the project root (use `.env.example` as template)
- Set `GEMINI_API_KEY=your_actual_key_here`
- Ensure the venv is activated

**2. Streamlit command not found**
```
command not found: streamlit
```
Solution:
```bash
pip install -r requirements.txt
streamlit run streamlit_app.py
```

**3. ChromaDB errors or corrupted vector store**
```
ChromaDB initialization error
```
Solution:
```bash
# Backup any important data, then delete the vector store
rm -rf chroma_db/
# Restart the app to rebuild
streamlit run streamlit_app.py
```

**4. Knowledge base not loading**
- Verify `knowledge_sources.json` paths exist and are correct
- Ensure `enabled: true` for sources you want loaded
- Check file permissions and formats (PDF text-based, not scanned images)
- For new knowledge, place files in `knowledge_base/` directory

**5. PDF extraction fails**
Solution:
- Ensure PDFs are text-based (not scanned images)
- Convert scanned PDFs using OCR tools (tesseract, etc.) first
- Try uploading via the UI with different PDFs to isolate the issue

**6. Slow response or timeout errors**
- Check your internet connection
- Verify Gemini API quota hasn't been exceeded
- Reduce query complexity (shorter, more specific questions)
- Increase `REQUEST_TIMEOUT` in `telecom_advisor_enhanced.py` if needed

**7. Environment activation issues**
```bash
# macOS/Linux
source .venv/bin/activate

# Windows
.venv\Scripts\activate

# Verify activation (prompt should show (.venv))
which python  # Should point to .venv/bin/python
```

## ï¿½ License

Educational project â€” free to use for learning.
